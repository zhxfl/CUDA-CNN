#Comment#

#NON_LINEARITY = NL_SIGMOID , NL_TANH , NL_RELU#

IS_GRADIENT_CHECKING = false;   #is true when debug#
BATCH_SIZE = 128;               #test image size should be divided with no remainder#

CHANNELS = 3;                   #1, 3, 4#
CROP = 8;                       #0<= crop <=imgSize#
SCALE = 0.0;                    #13% of ImgSize#
ROTATION = 0.0;                 #angle#
DISTORTION = 0.0;               #just for mnist#
SHOWIMAGE = false;               #show the images after transformation#
HORIZONTAL = true;              #horizontal reflection#
TEST_EPOCH = 10;                #the period to get the test dataset's error rate#
WHITE_NOISE = 0.0;


[
LAYER = DATA;
NAME  = data;
]
 
[
LAYER = CONV;
NAME  = conv1;
INPUT = data;
KERNEL_SIZE = 5;
PADDING = 2;
KERNEL_AMOUNT = 64;
WEIGHT_DECAY = 1e-6;
initW = 0.01;
initType = Bernoulli;           #Gaussian, Bernoulli#
]


[
LAYER = NIN;
NAME  = nin1;
INPUT = conv1;
WEIGHT_DECAY = 1e-6;
initW = 0.05;
initType = Bernoulli;           #Gaussian, Bernoulli#
NON_LINEARITY = NL_RELU;
]
     
[
LAYER = POOLING;
NAME  = pooling1;
INPUT = nin1;
POOLINGTYPE = max;
SIZE = 3;
SKIP = 2;
]

[  
LAYER = CONV;
NAME  = conv2;
INPUT = pooling1;
KERNEL_SIZE = 5;
PADDING = 2;
KERNEL_AMOUNT = 64;
WEIGHT_DECAY = 1e-6;
initW = 0.05;
initType = Bernoulli;           #Gaussian, Bernoulli#
]


[
LAYER = NIN;
NAME  = nin2;
INPUT = conv2;
WEIGHT_DECAY = 1e-6;
initW = 0.05;
initType = Bernoulli;           #Gaussian, Bernoulli#
NON_LINEARITY = NL_RELU;
]

[
LAYER = POOLING;
NAME  = pooling2;
INPUT = nin2;
POOLINGTYPE = max;
SIZE = 3;
SKIP = 2;
]

[
LAYER = BRANCHLAYER;
NAME  = branchlayer1;
INPUT = pooling2;
OUTPUTS = b1a,b1b;
]


#===================branchlayer1->b1a start===================#
[
LAYER = FC;
NAME  = fc1;
INPUT = branchlayer1;
SUBINPUT = b1a;
NUM_FULLCONNECT_NEURONS = 1024;
WEIGHT_DECAY = 1e-6;
DROPOUT_RATE = 0.5;
initW = 0.01;
NON_LINEARITY = NL_RELU;
initType = Bernoulli;           #Gaussian, Bernoulli#
]
#===================branchlayer1->b1a start===================#

[  
LAYER = CONV;
NAME  = conv3;
INPUT = branchlayer1;
SUBINPUT = b1b;
KERNEL_SIZE = 3;
PADDING = 0;
KERNEL_AMOUNT = 64;
WEIGHT_DECAY = 1e-6;
initW = 0.01;
initType = Bernoulli;           #Gaussian, Bernoulli#
NON_LINEARITY = NL_RELU;
]

[
LAYER = NIN;
NAME  = nin3;
INPUT = conv3;
WEIGHT_DECAY = 1e-6;
initW = 0.01;
initType = Bernoulli;           #Gaussian, Bernoulli#
NON_LINEARITY = NL_RELU;
]

#===============combineLayer1====================#

[
LAYER = COMBINELAYER;
NAME  = combineLayer1;
INPUTS= fc1, nin3;
]

[
LAYER = SOFTMAX;
NAME = softmax1;
INPUT = combineLayer1;
NUM_CLASSES = 10;
WEIGHT_DECAY = 1e-6;
initW = 0.05;
initType = Bernoulli;           #Gaussian, Bernoulli#
]
